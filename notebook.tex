
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Traffic\_Sign\_Classifier}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Self-Driving Car Engineer
Nanodegree}\label{self-driving-car-engineer-nanodegree}

\subsection{Deep Learning}\label{deep-learning}

\subsection{Project: Build a Traffic Sign Recognition
Classifier}\label{project-build-a-traffic-sign-recognition-classifier}

In this notebook, a template is provided for you to implement your
functionality in stages, which is required to successfully complete this
project. If additional code is required that cannot be included in the
notebook, be sure that the Python code is successfully imported and
included in your submission if necessary.

\begin{quote}
\textbf{Note}: Once you have completed all of the code implementations,
you need to finalize your work by exporting the iPython Notebook as an
HTML document. Before exporting the notebook to html, all of the code
cells need to have been run so that reviewers can see the final
implementation and output. You can then export the notebook by using the
menu above and navigating to \n", "\textbf{File -\textgreater{} Download
as -\textgreater{} HTML (.html)}. Include the finished document along
with this notebook as your submission.
\end{quote}

In addition to implementing code, there is a writeup to complete. The
writeup should be completed in a separate file, which can be either a
markdown file or a pdf document. There is a
\href{https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md}{write
up template} that can be used to guide the writing process. Completing
the code template and writeup template will cover all of the
\href{https://review.udacity.com/\#!/rubrics/481/view}{rubric points}
for this project.

The \href{https://review.udacity.com/\#!/rubrics/481/view}{rubric}
contains "Stand Out Suggestions" for enhancing the project beyond the
minimum requirements. The stand out suggestions are optional. If you
decide to pursue the "stand out suggestions", you can include the code
in this Ipython notebook and also discuss the results in the writeup
file.

\begin{quote}
\textbf{Note:} Code and Markdown cells can be executed using the
\textbf{Shift + Enter} keyboard shortcut. In addition, Markdown cells
can be edited by typically double-clicking the cell to enter edit mode.
\end{quote}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

The goals / steps of this project are the following: * Load the data set
(see below for links to the project data set) * Explore, summarize and
visualize the data set * Design, train and test a model architecture *
Use the model to make predictions on new images * Analyze the softmax
probabilities of the new images * Summarize the results with a written
report

\subsection{Step 0: Load The Data}\label{step-0-load-the-data}

    \subsubsection{Import all necessary
modules}\label{import-all-necessary-modules}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{random}
        \PY{k+kn}{import} \PY{n+nn}{cv2}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{shuffle}
        \PY{k+kn}{import} \PY{n+nn}{csv}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        \PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{contrib}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{flatten}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} Load pickled data}
        \PY{c+c1}{\PYZsh{} TODO: Fill this in based on where you saved the training and testing data}
        \PY{n}{training\PYZus{}file} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../data/train.p}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{validation\PYZus{}file} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../data/valid.p}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{testing\PYZus{}file} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../data/test.p}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{training\PYZus{}file}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
            \PY{n}{train} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{validation\PYZus{}file}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
            \PY{n}{valid} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{testing\PYZus{}file}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
            \PY{n}{test} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
            
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{labels}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{X\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{valid}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{labels}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{labels}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Map classID to traffic sign names.}
        \PY{n}{signs} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{signnames.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{csvfile}\PY{p}{:}
            \PY{n}{signnames} \PY{o}{=} \PY{n}{csv}\PY{o}{.}\PY{n}{reader}\PY{p}{(}\PY{n}{csvfile}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n+nb}{next}\PY{p}{(}\PY{n}{signnames}\PY{p}{,}\PY{k+kc}{None}\PY{p}{)}
            \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{signnames}\PY{p}{:}
                \PY{n}{signs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{row}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{n}{csvfile}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Step 1: Dataset Summary \&
Exploration}\label{step-1-dataset-summary-exploration}

The pickled data is a dictionary with 4 key/value pairs:

\begin{itemize}
\tightlist
\item
  \texttt{\textquotesingle{}features\textquotesingle{}} is a 4D array
  containing raw pixel data of the traffic sign images, (num examples,
  width, height, channels).
\item
  \texttt{\textquotesingle{}labels\textquotesingle{}} is a 1D array
  containing the label/class id of the traffic sign. The file
  \texttt{signnames.csv} contains id -\textgreater{} name mappings for
  each id.
\item
  \texttt{\textquotesingle{}sizes\textquotesingle{}} is a list
  containing tuples, (width, height) representing the original width and
  height the image.
\item
  \texttt{\textquotesingle{}coords\textquotesingle{}} is a list
  containing tuples, (x1, y1, x2, y2) representing coordinates of a
  bounding box around the sign in the image. \textbf{THESE COORDINATES
  ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS
  (32 by 32) OF THESE IMAGES}
\end{itemize}

Complete the basic data summary below. Use python, numpy and/or pandas
methods to calculate the data summary rather than hard coding the
results. For example, the
\href{http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html}{pandas
shape method} might be useful for calculating some of the summary
results.

    \subsubsection{Question 1:1. Provide a basic summary of the data set. In
the code, the analysis should be done using python, numpy and/or pandas
methods rather than hardcoding results
manually.}\label{question-11.-provide-a-basic-summary-of-the-data-set.-in-the-code-the-analysis-should-be-done-using-python-numpy-andor-pandas-methods-rather-than-hardcoding-results-manually.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Provide a Basic Summary of the Data Set Using Python,
Numpy and/or
Pandas}\label{provide-a-basic-summary-of-the-data-set-using-python-numpy-andor-pandas}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Replace each question mark with the appropriate value. }
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Use python, pandas or numpy methods rather than hard coding the results}
        
        \PY{c+c1}{\PYZsh{} TODO: Number of training examples}
        \PY{n}{n\PYZus{}train} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} TODO: Number of validation examples}
        \PY{n}{n\PYZus{}validation} \PY{o}{=} \PY{n}{X\PYZus{}valid}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} TODO: Number of testing examples.}
        \PY{n}{n\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} TODO: What\PYZsq{}s the shape of an traffic sign image?}
        \PY{n}{image\PYZus{}shape} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{shape}
        
        \PY{c+c1}{\PYZsh{} TODO: How many unique classes/labels there are in the dataset.}
        \PY{n}{n\PYZus{}classes} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of training examples =}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{n\PYZus{}train}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of testing examples =}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{n\PYZus{}test}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Image data shape =}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{image\PYZus{}shape}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of classes =}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{n\PYZus{}classes}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Number of training examples = 34799
Number of testing examples = 12630
Image data shape = (32, 32, 3)
Number of classes = 43

    \end{Verbatim}

    \subsubsection{Question 1:2. Include an exploratory visualization of the
dataset.}\label{question-12.-include-an-exploratory-visualization-of-the-dataset.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Include an exploratory visualization of the
dataset}\label{include-an-exploratory-visualization-of-the-dataset}

    Visualize the German Traffic Signs Dataset using the pickled file(s).
This is open ended, suggestions include: plotting traffic sign images,
plotting the count of each sign, etc.

The \href{http://matplotlib.org/}{Matplotlib}
\href{http://matplotlib.org/examples/index.html}{examples} and
\href{http://matplotlib.org/gallery.html}{gallery} pages are a great
resource for doing visualizations in Python.

\textbf{NOTE:} It's recommended you start with something simple first.
If you wish to do more, come back to it after you've completed the rest
of the sections. It can be interesting to look at the distribution of
classes in the training, validation and test set. Is the distribution
the same? Are there more examples of some classes than others?

    \paragraph{Visualize traffic sign images to understand their perspective
and
quality}\label{visualize-traffic-sign-images-to-understand-their-perspective-and-quality}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Data exploration visualization code goes here.}
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Feel free to use as many code cells as needed.}
        
        \PY{k}{def} \PY{n+nf}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{x\PYZus{}data}\PY{p}{,} \PY{n}{y\PYZus{}data}\PY{p}{,} \PY{n}{ylabel}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Visualizes few of the traffic sign images with their corresponding label.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}} 
            \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
                \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
                \PY{n}{indx} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x\PYZus{}data}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Set cmap = \PYZsq{}gray\PYZsq{}, color channel dimension doesn\PYZsq{}t exist}
                \PY{n}{cmap} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x\PYZus{}data}\PY{p}{[}\PY{n}{indx}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{)} \PY{o}{\PYZlt{}} \PY{l+m+mi}{3} \PY{k}{else} \PY{n}{cmap}
                \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{x\PYZus{}data}\PY{p}{[}\PY{n}{indx}\PY{p}{]}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{cmap}\PY{p}{)}
                \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{n}{signs}\PY{p}{[}\PY{n}{y\PYZus{}data}\PY{p}{[}\PY{n}{indx}\PY{p}{]}\PY{p}{]}\PY{p}{)}
                \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{n}{ylabel}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{n}{pad}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{h\PYZus{}pad}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{w\PYZus{}pad}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Plotting image samples from X\PYZus{}train, X\PYZus{}test and X\PYZus{}valid}
        \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training sample}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Testing sample}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{X\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation sample}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Plotting histogram to understand dataset distribution for
signs.}\label{plotting-histogram-to-understand-dataset-distribution-for-signs.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}histogram}\PY{p}{(}\PY{n}{x\PYZus{}input}\PY{p}{,} \PY{n}{xlabel}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}input}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{n}{n\PYZus{}classes}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{xlabel}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Traffic sign classes}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Image count}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{n\PYZus{}classes}\PY{p}{)}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{plot\PYZus{}histogram}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training set}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plot\PYZus{}histogram}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Testing set}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plot\PYZus{}histogram}\PY{p}{(}\PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation set}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Step 2: Design and Test a Model
Architecture}\label{step-2-design-and-test-a-model-architecture}

Design and implement a deep learning model that learns to recognize
traffic signs. Train and test your model on the
\href{http://benchmark.ini.rub.de/?section=gtsrb\&subsection=dataset}{German
Traffic Sign Dataset}.

The LeNet-5 implementation shown in the
\href{https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81}{classroom}
at the end of the CNN lesson is a solid starting point. You'll have to
change the number of classes and possibly the preprocessing, but aside
from that it's plug and play!

With the LeNet-5 solution from the lecture, you should expect a
validation set accuracy of about 0.89. To meet specifications, the
validation set accuracy will need to be at least 0.93. It is possible to
get an even higher accuracy, but 0.93 is the minimum for a successful
project submission.

There are various aspects to consider when thinking about this problem:

\begin{itemize}
\tightlist
\item
  Neural network architecture (is the network over or underfitting?)
\item
  Play around preprocessing techniques (normalization, rgb to grayscale,
  etc)
\item
  Number of examples per label (some have more than others).
\item
  Generate fake data.
\end{itemize}

Here is an example of a
\href{http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf}{published
baseline model on this problem}. It's not required to be familiar with
the approach used in the paper but, it's good practice to try to read
papers like these.

    \subsubsection{Question 2:1. Describe how you preprocessed the image
data. What techniques were chosen and why did you choose these
techniques? Consider including images showing the output of each
preprocessing technique. Pre-processing refers to techniques such as
converting to grayscale, normalization, etc. (OPTIONAL: As described in
the "Stand Out Suggestions" part of the rubric, if you generated
additional data for training, describe why you decided to generate
additional data, how you generated the data, and provide example images
of the additional data. Then describe the characteristics of the
augmented training set like number of images in the set, number of
images for each class,
etc.)}\label{question-21.-describe-how-you-preprocessed-the-image-data.-what-techniques-were-chosen-and-why-did-you-choose-these-techniques-consider-including-images-showing-the-output-of-each-preprocessing-technique.-pre-processing-refers-to-techniques-such-as-converting-to-grayscale-normalization-etc.-optional-as-described-in-the-stand-out-suggestions-part-of-the-rubric-if-you-generated-additional-data-for-training-describe-why-you-decided-to-generate-additional-data-how-you-generated-the-data-and-provide-example-images-of-the-additional-data.-then-describe-the-characteristics-of-the-augmented-training-set-like-number-of-images-in-the-set-number-of-images-for-each-class-etc.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Pre-process the Data Set (normalization, grayscale,
etc.)}\label{pre-process-the-data-set-normalization-grayscale-etc.}

    Minimally, the image data should be normalized so that the data has mean
zero and equal variance. For image data, \texttt{(pixel\ -\ 128)/\ 128}
is a quick way to approximately normalize the data and can be used in
this project.

Other pre-processing steps are optional. You can try different
techniques to see if it improves performance.

Use the code cell (or multiple code cells, if necessary) to implement
the first step of your project.

    \paragraph{Data Augmentation}\label{data-augmentation}

    For each image in the training data set we will generate/augment upto 8
variations for it using various data augmentation strategies

We have created several data augmentation helper functions

Perspective Warp: This function takes base input image and the type of
warping the user expects(from the defined types), it will warp the base
image to that perspective.

Rotate Image: This function takes base input image and the angle the
user expects the image to rotate, it will rotate the base image to the
passed angle.

Gaussian Noise: This function takes base input image, generates a
gaussian noise that maps the image dimensions and adds it to image.
(Note: Although I thought this function will be helpful for data
augmentation which will help build on accuracy, but even without its use
the base model is saturating to correct predictions very quickly, I
removed this to save on some parameters)

Gamma Correction: This function takes the base input image, builds a
lookup table by looping over all pixel values in the range {[}0, 255{]}.
The pixel value is then scaled to the range {[}0, 1.0{]} followed by
being raised to the power of the inverse gamma --- this value is then
stored in the table, next we use cv2.LUT to take the input image and the
table and find the correct mappings for each pixel value.

Blur: This function takes base input image, generates and applies a
gaussian blur the image by using cv2.GaussianBlur().

    Perspective Warp

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{tilt\PYZus{}type}\PY{p}{)}\PY{p}{:}
            \PY{n}{warp\PYZus{}img} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
            \PY{n}{wimg\PYZus{}size} \PY{o}{=} \PY{p}{(}\PY{n}{warp\PYZus{}img}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{warp\PYZus{}img}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
            
            \PY{k}{def} \PY{n+nf}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{n}{p1}\PY{p}{,} \PY{n}{p2}\PY{p}{,} \PY{n}{p3}\PY{p}{,} \PY{n}{p4}\PY{p}{)}\PY{p}{:}  
                \PY{n}{src\PYZus{}pts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{(}\PY{p}{[}
                    \PY{p}{[}\PY{n}{p1}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{p1}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{n}{p2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{p2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{n}{p3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{p3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{n}{p4}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{p4}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
                \PY{p}{]}\PY{p}{)}
        
                \PY{n}{dst\PYZus{}pts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{(}\PY{p}{[}
                    \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                    \PY{p}{[}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}
                \PY{p}{]}\PY{p}{)}
                \PY{k}{return} \PY{p}{(}\PY{n}{src\PYZus{}pts}\PY{p}{,} \PY{n}{dst\PYZus{}pts}\PY{p}{)}
            \PY{c+c1}{\PYZsh{}Tilt}
            \PY{n}{tilt\PYZus{}left} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.9}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.9}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{)}\PY{p}{)}
            \PY{n}{tilt\PYZus{}right} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            \PY{n}{tilt\PYZus{}front} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{)}\PY{p}{)}
            \PY{n}{tilt\PYZus{}back} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.9}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.9}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Sheer}
            \PY{n}{sheer\PYZus{}left} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            \PY{n}{sheer\PYZus{}right} \PY{o}{=} \PY{n}{get\PYZus{}source\PYZus{}dst\PYZus{}pts}\PY{p}{(}\PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mf}{0.85}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{wimg\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Tilt type to var mapping}
            \PY{n}{tilt\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{tilt\PYZus{}left}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{tilt\PYZus{}right}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{tilt\PYZus{}front}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{back}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{tilt\PYZus{}back}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sheer\PYZus{}left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{sheer\PYZus{}left}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sheer\PYZus{}right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{sheer\PYZus{}right}
            \PY{p}{\PYZcb{}}
            \PY{c+c1}{\PYZsh{} get source and destination co\PYZhy{}ordinated for passed in tilt\PYZus{}type}
            \PY{n}{tilt\PYZus{}cords} \PY{o}{=} \PY{n}{tilt\PYZus{}map}\PY{p}{[}\PY{n}{tilt\PYZus{}type}\PY{p}{]}
            \PY{n}{M} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{getPerspectiveTransform}\PY{p}{(}\PY{n}{tilt\PYZus{}cords}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{tilt\PYZus{}cords}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{n}{warped} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{warpPerspective}\PY{p}{(}\PY{n}{warp\PYZus{}img}\PY{p}{,} \PY{n}{M}\PY{p}{,} \PY{n}{wimg\PYZus{}size}\PY{p}{,} \PY{n}{flags}\PY{o}{=}\PY{n}{cv2}\PY{o}{.}\PY{n}{INTER\PYZus{}LINEAR}\PY{p}{)}
            \PY{k}{return} \PY{n}{warped}
\end{Verbatim}


    Rotate Image

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k}{def} \PY{n+nf}{rotate\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{angle}\PY{p}{)}\PY{p}{:}
             \PY{n}{rot\PYZus{}img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             \PY{n}{image\PYZus{}center} \PY{o}{=} \PY{n+nb}{tuple}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rot\PYZus{}img}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
             \PY{n}{rot\PYZus{}mat} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{getRotationMatrix2D}\PY{p}{(}\PY{n}{image\PYZus{}center}\PY{p}{,} \PY{n}{angle}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{)}
             \PY{n}{result} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{warpAffine}\PY{p}{(}\PY{n}{rot\PYZus{}img}\PY{p}{,} \PY{n}{rot\PYZus{}mat}\PY{p}{,} \PY{n}{rot\PYZus{}img}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{flags}\PY{o}{=}\PY{n}{cv2}\PY{o}{.}\PY{n}{INTER\PYZus{}LINEAR}\PY{p}{)}
             \PY{k}{return} \PY{n}{result}
\end{Verbatim}


    Gaussian Noise

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k}{def} \PY{n+nf}{add\PYZus{}gauss\PYZus{}noise}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{:}
             \PY{n}{noisy\PYZus{}img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             \PY{n}{row}\PY{p}{,}\PY{n}{col}\PY{o}{=} \PY{n}{noisy\PYZus{}img}\PY{o}{.}\PY{n}{shape}
             \PY{n}{mean} \PY{o}{=} \PY{l+m+mi}{0}
             \PY{n}{var} \PY{o}{=} \PY{l+m+mf}{0.1}
             \PY{n}{sigma} \PY{o}{=} \PY{n}{var}\PY{o}{*}\PY{o}{*}\PY{l+m+mf}{0.5}
             \PY{n}{gauss} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{mean}\PY{p}{,}\PY{n}{sigma}\PY{p}{,}\PY{p}{(}\PY{n}{row}\PY{p}{,}\PY{n}{col}\PY{p}{)}\PY{p}{)}
             \PY{n}{gauss} \PY{o}{=} \PY{n}{gauss}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{row}\PY{p}{,}\PY{n}{col}\PY{p}{)}
             \PY{n}{noisy} \PY{o}{=} \PY{p}{(}\PY{n}{gauss} \PY{o}{+} \PY{n}{noisy\PYZus{}img}\PY{p}{)}
             \PY{n}{noisy} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{normalize}\PY{p}{(}\PY{n}{noisy}\PY{p}{,}\PY{k+kc}{None}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{255}\PY{p}{,}\PY{n}{cv2}\PY{o}{.}\PY{n}{NORM\PYZus{}MINMAX}\PY{p}{)}
             \PY{k}{return} \PY{n}{noisy}
\end{Verbatim}


    Gamma Correction

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k}{def} \PY{n+nf}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{)}\PY{p}{:}
             \PY{n}{g\PYZus{}img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             \PY{n}{invGamma} \PY{o}{=} \PY{l+m+mf}{1.0} \PY{o}{/} \PY{n}{gamma}
             \PY{n}{table} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{(}\PY{p}{(}\PY{n}{i} \PY{o}{/} \PY{l+m+mf}{255.0}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{n}{invGamma}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{255}
               \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uint8}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{LUT}\PY{p}{(}\PY{n}{g\PYZus{}img}\PY{p}{,} \PY{n}{table}\PY{p}{)}
\end{Verbatim}


    Blur

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k}{def} \PY{n+nf}{blur\PYZus{}img}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{:}
             \PY{n}{blurred\PYZus{}img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{GaussianBlur}\PY{p}{(}\PY{n}{blurred\PYZus{}img}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


    Data Augmentation Pipeline

    Augmentation pipleline for single image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{k}{def} \PY{n+nf}{augment\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{label}\PY{p}{)}\PY{p}{:}
             \PY{n}{aug\PYZus{}img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Define augmentation container for a single image}
             \PY{n}{aug\PYZus{}x} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{aug\PYZus{}y} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             
             \PY{c+c1}{\PYZsh{} Original Image Type 0}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 1}
             \PY{n}{aug\PYZus{}img1} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img1} \PY{o}{=} \PY{n}{rotate\PYZus{}image}\PY{p}{(}\PY{n}{aug\PYZus{}img1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{3}\PY{p}{)}
             \PY{n}{aug\PYZus{}img1} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img1}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img1}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 2}
             \PY{n}{aug\PYZus{}img2} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img2} \PY{o}{=} \PY{n}{rotate\PYZus{}image}\PY{p}{(}\PY{n}{aug\PYZus{}img2}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
             \PY{n}{aug\PYZus{}img2} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img2}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img2}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 3}
             \PY{n}{aug\PYZus{}img3} \PY{o}{=} \PY{n}{rotate\PYZus{}image}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{)}
             \PY{n}{aug\PYZus{}img3} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img3}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img3}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 4}
             \PY{n}{aug\PYZus{}img4} \PY{o}{=} \PY{n}{rotate\PYZus{}image}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
             \PY{n}{aug\PYZus{}img4} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img4}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img4}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 5}
             \PY{n}{aug\PYZus{}img5} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img5} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img5}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sheer\PYZus{}left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img5} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img5}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{1.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img5}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 6}
             \PY{n}{aug\PYZus{}img6} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img6} \PY{o}{=} \PY{n}{perspective\PYZus{}warp}\PY{p}{(}\PY{n}{aug\PYZus{}img6}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sheer\PYZus{}right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{aug\PYZus{}img6} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img6}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{1.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img6}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 7}
             \PY{n}{aug\PYZus{}img7} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}img7} \PY{o}{=} \PY{n}{blur\PYZus{}img}\PY{p}{(}\PY{n}{aug\PYZus{}img7}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img7}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Augmented Image Type 8}
             \PY{n}{aug\PYZus{}img8} \PY{o}{=} \PY{n}{adjust\PYZus{}gamma}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{1.5}\PY{p}{)}
             \PY{n}{aug\PYZus{}img8} \PY{o}{=} \PY{n}{blur\PYZus{}img}\PY{p}{(}\PY{n}{aug\PYZus{}img8}\PY{p}{)}
             \PY{n}{aug\PYZus{}x}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img8}\PY{p}{)}
             \PY{n}{aug\PYZus{}y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{label}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Return both containers}
             \PY{k}{return} \PY{n}{aug\PYZus{}x}\PY{p}{,} \PY{n}{aug\PYZus{}y}
\end{Verbatim}


    Augmentation pipleline for multiple images.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{k}{def} \PY{n+nf}{augment\PYZus{}data}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}\PY{p}{:}
             \PY{n}{aug\PYZus{}all\PYZus{}x} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{aug\PYZus{}all\PYZus{}y} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{X}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} Augment image at position X[i] and alocate its label as Y[i]}
                 \PY{n}{aug\PYZus{}x}\PY{p}{,} \PY{n}{aug\PYZus{}y} \PY{o}{=} \PY{n}{augment\PYZus{}image}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{Y}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
                 \PY{n}{aug\PYZus{}all\PYZus{}x}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{aug\PYZus{}x}\PY{p}{)}
                 \PY{n}{aug\PYZus{}all\PYZus{}y}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{aug\PYZus{}y}\PY{p}{)}
             \PY{n}{aug\PYZus{}all\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{aug\PYZus{}all\PYZus{}x}\PY{p}{)}
             \PY{n}{aug\PYZus{}all\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{aug\PYZus{}all\PYZus{}y}\PY{p}{)}
             \PY{k}{return} \PY{n}{aug\PYZus{}all\PYZus{}x}\PY{p}{,} \PY{n}{aug\PYZus{}all\PYZus{}y}
\end{Verbatim}


    \paragraph{Grayscaling}\label{grayscaling}

    In their paper "Traffic Sign Recognition with Multi-Scale Convolutional
Networks" published in 2011, P. Sermanet and Y. LeCun stated that using
grayscale images instead of color improves the ConvNet's accuracy. We
will use OpenCV to convert the training images into gray scale.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}grayscale}\PY{p}{(}\PY{n}{rgb\PYZus{}image}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Convert RGB image to grayscale}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{rgb\PYZus{}image}\PY{p}{,} \PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}RGB2GRAY}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} Convert RGB input training images to grayscale using our get\PYZus{}grayscale func}
         \PY{n}{grayscale\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{get\PYZus{}grayscale}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{)}
         \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{grayscale\PYZus{}imgs}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gray Scale image}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_46_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Histogram Equalization}\label{histogram-equalization}

    Histogram equalization is a technique for adjusting image intensities to
enhance contrast. Since from the dataset it is clear and more obvious
that(due to fog or low light conditions many images of traffic signs
might have low contrast)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{k}{def} \PY{n+nf}{equalize\PYZus{}hist}\PY{p}{(}\PY{n}{unequalized\PYZus{}img}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Apply Histogram Equalization on grayscaled images}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{eq\PYZus{}img} \PY{o}{=} \PY{n}{unequalized\PYZus{}img}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)} 
             \PY{n}{eq\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{equalizeHist}\PY{p}{(}\PY{n}{eq\PYZus{}img}\PY{p}{)}
             \PY{k}{return} \PY{n}{eq\PYZus{}img}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} Perform histogram equalization on the training images.}
         \PY{n}{equalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{equalize\PYZus{}hist}\PY{p}{,} \PY{n}{grayscale\PYZus{}imgs}\PY{p}{)}\PY{p}{)}
         \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{equalized\PYZus{}imgs}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Equalized Image}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_50_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Normalization}\label{normalization}

    Normalization is a process that changes the range of pixel intensity
values. Usually the image data should be normalized so that the data has
mean zero and equal variance.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{k}{def} \PY{n+nf}{normalize\PYZus{}img}\PY{p}{(}\PY{n}{non\PYZus{}normalized\PYZus{}img}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Normalize images pixel values.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{normalized\PYZus{}img} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{divide}\PY{p}{(}\PY{n}{non\PYZus{}normalized\PYZus{}img}\PY{p}{,} \PY{l+m+mi}{255}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}normalized\PYZus{}img = np.divide(np.subtract(non\PYZus{}normalized\PYZus{}img, 128), 128)}
             \PY{k}{return} \PY{n}{normalized\PYZus{}img}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} Perform normalization on the training images.}
         \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{normalize\PYZus{}img}\PY{p}{,} \PY{n}{equalized\PYZus{}imgs}\PY{p}{)}\PY{p}{)}
         \PY{n}{visualize\PYZus{}sign\PYZus{}images}\PY{p}{(}\PY{n}{normalized\PYZus{}imgs}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Normalized Image}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_54_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Construct pre-processing
pipeline}\label{construct-pre-processing-pipeline}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Sequentially apply previously crafted pre\PYZhy{}processing functions over the input data.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{c+c1}{\PYZsh{} Grayscale}
             \PY{n}{grayscale\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{get\PYZus{}grayscale}\PY{p}{,} \PY{n}{X\PYZus{}data}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Histogram equalization}
             \PY{n}{equalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{equalize\PYZus{}hist}\PY{p}{,} \PY{n}{grayscale\PYZus{}imgs}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Normalization}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{normalize\PYZus{}img}\PY{p}{,} \PY{n}{equalized\PYZus{}imgs}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Convert to np array and reshape to 4 dimensions}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{normalized\PYZus{}imgs}\PY{p}{)}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n}{normalized\PYZus{}imgs}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Return pre\PYZhy{}processed input data}
             \PY{k}{return} \PY{n}{normalized\PYZus{}imgs}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{k}{def} \PY{n+nf}{augment\PYZus{}train\PYZus{}data}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{,} \PY{n}{Y\PYZus{}data}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    (Similar pipeline to preprocessing) Sequentially apply previously crafted pre\PYZhy{}processing functions over the input data.}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{c+c1}{\PYZsh{} Grayscale}
             \PY{n}{grayscale\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{get\PYZus{}grayscale}\PY{p}{,} \PY{n}{X\PYZus{}data}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Histogram equalization}
             \PY{n}{equalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{equalize\PYZus{}hist}\PY{p}{,} \PY{n}{grayscale\PYZus{}imgs}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Augment}
             \PY{n}{aug\PYZus{}all\PYZus{}x}\PY{p}{,} \PY{n}{aug\PYZus{}all\PYZus{}y} \PY{o}{=} \PY{n}{augment\PYZus{}data}\PY{p}{(}\PY{n}{equalized\PYZus{}imgs}\PY{p}{,} \PY{n}{Y\PYZus{}data}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Normalization}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{normalize\PYZus{}img}\PY{p}{,} \PY{n}{aug\PYZus{}all\PYZus{}x}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Convert to np array and reshape to 4 dimensions}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{normalized\PYZus{}imgs}\PY{p}{)}
             \PY{n}{normalized\PYZus{}imgs} \PY{o}{=} \PY{n}{normalized\PYZus{}imgs}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Return pre\PYZhy{}processed input data}
             \PY{k}{return} \PY{n}{normalized\PYZus{}imgs}\PY{p}{,} \PY{n}{aug\PYZus{}all\PYZus{}y}
\end{Verbatim}


    \paragraph{Apply augmentation on training
data}\label{apply-augmentation-on-training-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train} \PY{o}{=} \PY{n}{augment\PYZus{}train\PYZus{}data}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \paragraph{Save/Pickel the training
data}\label{savepickel-the-training-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{augmented\PYZus{}data/X\PYZus{}train.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{f}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{augmented\PYZus{}data/y\PYZus{}train.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{aug\PYZus{}y\PYZus{}train}\PY{p}{,} \PY{n}{f}\PY{p}{)}
\end{Verbatim}


    \paragraph{Load the pickled training
data}\label{load-the-pickled-training-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{augmented\PYZus{}data/X\PYZus{}train.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{aug\PYZus{}X\PYZus{}train} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{augmented\PYZus{}data/y\PYZus{}train.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{aug\PYZus{}y\PYZus{}train} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}30}]:} (313191, 32, 32, 1)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{80900}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{)}\PY{p}{,}\PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}31}]:} <matplotlib.image.AxesImage at 0x237c0c65898>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_67_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Shuffle training data}\label{shuffle-training-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}33}]:} (313191, 32, 32, 1)
\end{Verbatim}
            
    \subsubsection{Question 2:2. Describe what your final model architecture
looks like including model type, layers, layer sizes, connectivity,
etc.) Consider including a diagram and/or table describing the final
model.}\label{question-22.-describe-what-your-final-model-architecture-looks-like-including-model-type-layers-layer-sizes-connectivity-etc.-consider-including-a-diagram-andor-table-describing-the-final-model.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Model Architecture}\label{model-architecture}

    The final goal here is to build a model that can cross/reach an accuracy
of over 97\% on the validation set. We will be using a streamed down
version of VGG model architecture here in order to reduce number of
parameters and computation, the exact architecture is defined below.

This ConvNet follows these steps:

Input =\textgreater{} Convolution =\textgreater{} ReLU =\textgreater{}
Convolution =\textgreater{} ReLU =\textgreater{} Pooling =\textgreater{}
Convolution =\textgreater{} ReLU =\textgreater{} Convolution
=\textgreater{} ReLU =\textgreater{} Pooling =\textgreater{} Convolution
=\textgreater{} ReLU =\textgreater{} Convolution =\textgreater{} ReLU
=\textgreater{} Pooling =\textgreater{} FullyConnected =\textgreater{}
ReLU =\textgreater{} FullyConnected =\textgreater{} ReLU =\textgreater{}
FullyConnected

    

    \paragraph{Summary of VGG Net}\label{summary-of-vgg-net}

The VGG network architecture was introduced by Simonyan and Zisserman in
their 2014 paper, Very Deep Convolutional Networks for Large Scale Image
Recognition.

This network is characterized by its simplicity, using only 3×3
convolutional layers stacked on top of each other in increasing depth.
Reducing volume size is handled by max pooling. Two fully-connected
layers, each with 4,096 nodes are then followed by a softmax classifier
(above). In 2014, 16 and 19 layer networks were considered very deep
(although we now have the ResNet architecture which can be successfully
trained at depths of 50-200 for ImageNet and over 1,000 for CIFAR-10).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{k}{class} \PY{n+nc}{VGGnet}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{n\PYZus{}out}\PY{o}{=}\PY{l+m+mi}{43}\PY{p}{,} \PY{n}{mu}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} Hyperparameters}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu} \PY{o}{=} \PY{n}{mu}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma} \PY{o}{=} \PY{n}{sigma}
         
                 \PY{c+c1}{\PYZsh{} Layer 1 (Convolutional): Input = 32x32x1. Output = 32x32x32.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Layer 2 (Convolutional): Input = 32x32x32. Output = 32x32x32.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Layer 3 (Pooling): Input = 32x32x32. Output = 16x16x32.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{max\PYZus{}pool}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2}\PY{p}{,} \PY{n}{ksize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VALID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Layer 4 (Convolutional): Input = 16x16x32. Output = 16x16x64.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Layer 5 (Convolutional): Input = 16x16x64. Output = 16x16x64.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Layer 6 (Pooling): Input = 16x16x64. Output = 8x8x64.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{max\PYZus{}pool}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4}\PY{p}{,} \PY{n}{ksize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VALID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{)} \PY{c+c1}{\PYZsh{} dropout}
         
                 \PY{c+c1}{\PYZsh{} Layer 7 (Convolutional): Input = 8x8x64. Output = 8x8x128.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Layer 8 (Convolutional): Input = 8x8x128. Output = 8x8x128.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv5}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6\PYZus{}W}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6\PYZus{}b}
                 
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Layer 9 (Pooling): Input = 8x8x128. Output = 4x4x128.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{max\PYZus{}pool}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6}\PY{p}{,} \PY{n}{ksize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VALID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{)} \PY{c+c1}{\PYZsh{} dropout}
         
                 \PY{c+c1}{\PYZsh{} Flatten. Input = 4x4x128. Output = 2048.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc0} \PY{o}{=} \PY{n}{flatten}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv6}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Layer 10 (Fully Connected): Input = 2048. Output = 128.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2048}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc0}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1\PYZus{}W}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1\PYZus{}b}
         
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{,} \PY{n}{keep\PYZus{}prob}\PY{p}{)} \PY{c+c1}{\PYZsh{} dropout}
         
                 \PY{c+c1}{\PYZsh{} Layer 11 (Fully Connected): Input = 128. Output = 128.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2\PYZus{}W}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2\PYZus{}b}
         
                 \PY{c+c1}{\PYZsh{} ReLu Activation.}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{,} \PY{n}{keep\PYZus{}prob}\PY{p}{)} \PY{c+c1}{\PYZsh{} dropout}
         
                 \PY{c+c1}{\PYZsh{} Layer 12 (Fully Connected): Input = 128. Output = n\PYZus{}out(43)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3\PYZus{}W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{n}{n\PYZus{}out}\PY{p}{)}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{mu}\PY{p}{,} \PY{n}{stddev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sigma}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3\PYZus{}b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{n\PYZus{}out}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3\PYZus{}W}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3\PYZus{}b}
         
                 \PY{c+c1}{\PYZsh{} Training operation}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{one\PYZus{}hot\PYZus{}y} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{one\PYZus{}hot}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{n\PYZus{}out}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{cross\PYZus{}entropy} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{softmax\PYZus{}cross\PYZus{}entropy\PYZus{}with\PYZus{}logits\PYZus{}v2}\PY{p}{(}\PY{n}{logits}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits}\PY{p}{,} \PY{n}{labels}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{one\PYZus{}hot\PYZus{}y}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss\PYZus{}operation} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{cross\PYZus{}entropy}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate} \PY{o}{=} \PY{n}{learning\PYZus{}rate}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{training\PYZus{}operation} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{optimizer}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss\PYZus{}operation}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Accuracy operation}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{correct\PYZus{}prediction} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{equal}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{one\PYZus{}hot\PYZus{}y}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{accuracy\PYZus{}operation} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{cast}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{correct\PYZus{}prediction}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{} Saving all variables}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{saver} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{Saver}\PY{p}{(}\PY{p}{)}
                 
             \PY{k}{def} \PY{n+nf}{y\PYZus{}predict}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}data}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{)}\PY{p}{:}
                 \PY{n}{num\PYZus{}examples} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{)}
                 \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}examples}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{int32}\PY{p}{)}
                 \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}session}\PY{p}{(}\PY{p}{)}
                 \PY{k}{for} \PY{n}{offset} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{num\PYZus{}examples}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{p}{)}\PY{p}{:}
                     \PY{n}{batch\PYZus{}x} \PY{o}{=} \PY{n}{X\PYZus{}data}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{offset}\PY{o}{+}\PY{n}{BATCH\PYZus{}SIZE}\PY{p}{]}
                     \PY{n}{y\PYZus{}pred}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{offset}\PY{o}{+}\PY{n}{BATCH\PYZus{}SIZE}\PY{p}{]} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} 
                                        \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:}\PY{n}{batch\PYZus{}x}\PY{p}{,} \PY{n}{keep\PYZus{}prob}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{\PYZcb{}}\PY{p}{)}
                 \PY{k}{return} \PY{n}{y\PYZus{}pred}
             
             \PY{k}{def} \PY{n+nf}{evaluate}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}data}\PY{p}{,} \PY{n}{y\PYZus{}data}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{)}\PY{p}{:}
                 \PY{n}{num\PYZus{}examples} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{)}
                 \PY{n}{total\PYZus{}accuracy} \PY{o}{=} \PY{l+m+mi}{0}
                 \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}session}\PY{p}{(}\PY{p}{)}
                 \PY{k}{for} \PY{n}{offset} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{num\PYZus{}examples}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{p}{)}\PY{p}{:}
                     \PY{n}{batch\PYZus{}x}\PY{p}{,} \PY{n}{batch\PYZus{}y} \PY{o}{=} \PY{n}{X\PYZus{}data}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{offset}\PY{o}{+}\PY{n}{BATCH\PYZus{}SIZE}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}data}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{offset}\PY{o}{+}\PY{n}{BATCH\PYZus{}SIZE}\PY{p}{]}
                     \PY{n}{accuracy} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{accuracy\PYZus{}operation}\PY{p}{,} 
                                         \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{batch\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{:} \PY{n}{batch\PYZus{}y}\PY{p}{,} \PY{n}{keep\PYZus{}prob}\PY{p}{:} \PY{l+m+mf}{1.0}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{:} \PY{l+m+mf}{1.0} \PY{p}{\PYZcb{}}\PY{p}{)}
                     \PY{n}{total\PYZus{}accuracy} \PY{o}{+}\PY{o}{=} \PY{p}{(}\PY{n}{accuracy} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{batch\PYZus{}x}\PY{p}{)}\PY{p}{)}
                 \PY{k}{return} \PY{n}{total\PYZus{}accuracy} \PY{o}{/} \PY{n}{num\PYZus{}examples}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{n}{x} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{p}{(}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n}{y} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{(}\PY{k+kc}{None}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{keep\PYZus{}prob} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)} \PY{c+c1}{\PYZsh{} For fully\PYZhy{}connected layers}
         \PY{n}{keep\PYZus{}prob\PYZus{}conv} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)} \PY{c+c1}{\PYZsh{} For convolutional layers}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{n}{EPOCHS} \PY{o}{=} \PY{l+m+mi}{10}
         \PY{n}{BATCH\PYZus{}SIZE} \PY{o}{=} \PY{l+m+mi}{150} \PY{c+c1}{\PYZsh{} Tested: BATCH\PYZus{}SIZE = 65 to be more accurate(but a bit slow for training)}
         \PY{n}{DIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Saved\PYZus{}Models}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}38}]:} (32, 32, 1)
\end{Verbatim}
            
    \subsubsection{Question 2:3. Describe how you trained your model. The
discussion can include the type of optimizer, the batch size, number of
epochs and any hyperparameters such as learning
rate.}\label{question-23.-describe-how-you-trained-your-model.-the-discussion-can-include-the-type-of-optimizer-the-batch-size-number-of-epochs-and-any-hyperparameters-such-as-learning-rate.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Train, Validate and Test the
Model}\label{train-validate-and-test-the-model}

    A validation set can be used to assess how well the model is performing.
A low accuracy on the training and validation sets imply underfitting. A
high accuracy on the training set but low accuracy on the validation set
implies overfitting.

    We will train our network in the following way: - Before each epoch,
we'll shuffle the training set. - Train the model on training data set
in batches which are preprocessed, augmented and normalized. - We will
be using dropout with hyperparameters for dropout rates as keep\_prob
and keep\_prob\_conv for layers in our neural network. Deep Neural
networks are likely to quickly overfit a training dataset with few
examples. This has the effect of the model learning the statistical
noise in the training data, which results in poor performance when the
model is evaluated on new data, e.g. a test dataset. Generalization
error increases due to overfitting. Dropout is a regularization method
that approximates training a large number of neural networks with
different architectures in parallel. During training, some number of
layer outputs are randomly ignored or ``dropped out.'' This has the
effect of making the layer look-like and be treated-like a layer with a
different number of nodes and connectivity to the prior layer. Dropout
has the effect of making the training process noisy, forcing nodes
within a layer to probabilistically take on more or less responsibility
for the inputs. - We specify the learning rate of 0.001, it helps us
control on how much we are letting the model adjust the weights of
network with respect the loss gradient. - We minimize the loss function
using the Adaptive Moment Estimation (Adam) Algorithm, it is an
extension to stochastic gradient descent. However it is different to
classical stochastic gradient descent. It is designed to combine the
advantages of two other extensions of stochastic gradient descent which
are Adaptive Gradient Algorithm (AdaGrad) and Root Mean Square
Propagation (RMSProp). This algorithm calculates an exponential moving
average of the gradient and the squared gradient, and the parameters
beta1 and beta2 control the decay rates of these moving averages. -
Calculate softmax cross entropy between predictions and labels. -
Evaluate the error. - We run minimize() function on the optimizer which
use backprobagation to update the network and minimize our training
loss. - After each epoch, we measure the loss and accuracy of the
validation set. - A low accuracy on the training and validation sets
imply underfitting. A high accuracy on the training set but low accuracy
on the validation set implies overfitting. - We save the model with
final learned parameters.

    \paragraph{Run our constructed tensorflow graph inside session passing
batches to the above crafted
graph}\label{run-our-constructed-tensorflow-graph-inside-session-passing-batches-to-the-above-crafted-graph}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{n}{VGGNet\PYZus{}Model} \PY{o}{=} \PY{n}{VGGnet}\PY{p}{(}\PY{n}{n\PYZus{}out} \PY{o}{=} \PY{n}{n\PYZus{}classes}\PY{p}{)}
         \PY{n}{model\PYZus{}name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VGGNet}\PY{l+s+s2}{\PYZdq{}}
         
         \PY{c+c1}{\PYZsh{} Validation set preprocessing}
         \PY{n}{X\PYZus{}valid\PYZus{}preprocessed} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{X\PYZus{}valid}\PY{p}{)}
         \PY{n}{one\PYZus{}hot\PYZus{}y\PYZus{}valid} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{one\PYZus{}hot}\PY{p}{(}\PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{43}\PY{p}{)}
         
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{global\PYZus{}variables\PYZus{}initializer}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{num\PYZus{}examples} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{aug\PYZus{}y\PYZus{}train}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{EPOCHS}\PY{p}{)}\PY{p}{:}
                 \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train}\PY{p}{)}
                 \PY{k}{for} \PY{n}{offset} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{num\PYZus{}examples}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{p}{)}\PY{p}{:}
                     \PY{n}{end} \PY{o}{=} \PY{n}{offset} \PY{o}{+} \PY{n}{BATCH\PYZus{}SIZE}
                     \PY{n}{batch\PYZus{}x}\PY{p}{,} \PY{n}{batch\PYZus{}y} \PY{o}{=} \PY{n}{aug\PYZus{}X\PYZus{}train}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{end}\PY{p}{]}\PY{p}{,} \PY{n}{aug\PYZus{}y\PYZus{}train}\PY{p}{[}\PY{n}{offset}\PY{p}{:}\PY{n}{end}\PY{p}{]}
                     \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{training\PYZus{}operation}\PY{p}{,} 
                     \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{batch\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{:} \PY{n}{batch\PYZus{}y}\PY{p}{,} \PY{n}{keep\PYZus{}prob} \PY{p}{:} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{:} \PY{l+m+mf}{0.7}\PY{p}{\PYZcb{}}\PY{p}{)}
         
                 \PY{n}{validation\PYZus{}accuracy} \PY{o}{=} \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}valid\PYZus{}preprocessed}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EPOCH }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ : Validation Accuracy = }\PY{l+s+si}{\PYZob{}:.3f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{p}{(}\PY{n}{validation\PYZus{}accuracy}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{saver}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{DIR}\PY{p}{,} \PY{n}{model\PYZus{}name}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model saved}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Training{\ldots}

EPOCH 1 : Validation Accuracy = 96.440\%
EPOCH 2 : Validation Accuracy = 98.277\%
EPOCH 3 : Validation Accuracy = 98.753\%
EPOCH 4 : Validation Accuracy = 99.342\%
EPOCH 5 : Validation Accuracy = 99.252\%
EPOCH 6 : Validation Accuracy = 99.320\%
EPOCH 7 : Validation Accuracy = 99.433\%
EPOCH 8 : Validation Accuracy = 99.478\%
EPOCH 9 : Validation Accuracy = 99.478\%
EPOCH 10 : Validation Accuracy = 99.342\%
Model saved

    \end{Verbatim}

    We received a validation accuracy of +95\% right from the first epoch
while the model starts saturating from 5th epoch, these are great
metrics to obtain. The augmented data paved a way for our model to have
larger dataset to train with.

    \paragraph{Testing on test data}\label{testing-on-test-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{X\PYZus{}test\PYZus{}preprocessed} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{saver}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{DIR}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VGGNet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{y\PYZus{}predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}preprocessed}\PY{p}{)}
             \PY{n}{test\PYZus{}accuracy} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}test} \PY{o}{==} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}\PY{o}{/}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Accuracy = }\PY{l+s+si}{\PYZob{}:.1f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{test\PYZus{}accuracy}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from Saved\_Models\textbackslash{}VGGNet
Test Accuracy = 98.0\%

    \end{Verbatim}

    \paragraph{Confusion matrix}\label{confusion-matrix}

    By inspecting the confusion matrix it is clear to us where the model is
failing.

Most prominent and noticable failure occures when the model is trying to
predict speed limit traffic sign

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{c\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}
         \PY{n}{c\PYZus{}matrix} \PY{o}{=} \PY{n}{c\PYZus{}matrix}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{/} \PY{n}{c\PYZus{}matrix}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{newaxis}\PY{p}{]}
         \PY{n}{c\PYZus{}matrix} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{o}{.}\PY{l+m+mi}{0001} \PY{o}{+} \PY{n}{c\PYZus{}matrix}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{c\PYZus{}matrix}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nearest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Reds}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_95_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Question 2:4. Describe the approach taken for finding a
solution and getting the validation set accuracy to be at least 0.93.
Include in the discussion the results on the training, validation and
test sets and where in the code these were calculated. Your approach may
have been an iterative process, in which case, outline the steps you
took to get to the final solution and why you chose those steps. Perhaps
your solution involved an already well known implementation or
architecture. In this case, discuss why you think the architecture is
suitable for the current
problem.}\label{question-24.-describe-the-approach-taken-for-finding-a-solution-and-getting-the-validation-set-accuracy-to-be-at-least-0.93.-include-in-the-discussion-the-results-on-the-training-validation-and-test-sets-and-where-in-the-code-these-were-calculated.-your-approach-may-have-been-an-iterative-process-in-which-case-outline-the-steps-you-took-to-get-to-the-final-solution-and-why-you-chose-those-steps.-perhaps-your-solution-involved-an-already-well-known-implementation-or-architecture.-in-this-case-discuss-why-you-think-the-architecture-is-suitable-for-the-current-problem.}

    \paragraph{Answer:}\label{answer}

\subsubsection{Answer at bottom in 'Conclusion Section' (Placed at the
bottom since this wasn't a proper place to keep that
answer.}\label{answer-at-bottom-in-conclusion-section-placed-at-the-bottom-since-this-wasnt-a-proper-place-to-keep-that-answer.}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Step 3: Test a Model on New
Images}\label{step-3-test-a-model-on-new-images}

To give yourself more insight into how your model is working, download
at least five pictures of German traffic signs from the web and use your
model to predict the traffic sign type.

You may find \texttt{signnames.csv} useful as it contains mappings from
the class id (integer) to the actual sign name.

    \subsubsection{Question 3:1. Choose five German traffic signs found on
the web and provide them in the report. For each image, discuss what
quality or qualities might be difficult to
classify.}\label{question-31.-choose-five-german-traffic-signs-found-on-the-web-and-provide-them-in-the-report.-for-each-image-discuss-what-quality-or-qualities-might-be-difficult-to-classify.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Load and Output the
Images}\label{load-and-output-the-images}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{k+kn}{import} \PY{n+nn}{glob}
         \PY{n}{new\PYZus{}imgs\PYZus{}container} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{new\PYZus{}img\PYZus{}names} \PY{o}{=} \PY{n}{glob}\PY{o}{.}\PY{n}{glob}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}new\PYZus{}images/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{*.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{k}{for} \PY{n}{new\PYZus{}img\PYZus{}name} \PY{o+ow}{in} \PY{n}{new\PYZus{}img\PYZus{}names}\PY{p}{:}
             \PY{n}{new\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{new\PYZus{}img\PYZus{}name}\PY{p}{)}
             \PY{n}{new\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{new\PYZus{}img}\PY{p}{,} \PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}BGR2RGB}\PY{p}{)}
             \PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{new\PYZus{}img}\PY{p}{)}
         \PY{n}{new\PYZus{}imgs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{p}{)}
         \PY{n}{preprocessed\PYZus{}new\PYZus{}imgs} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{new\PYZus{}imgs}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
             \PY{n}{label\PYZus{}str} \PY{o}{=} \PY{n}{new\PYZus{}img\PYZus{}names}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{n}{signs}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{n}{label\PYZus{}str}\PY{p}{)}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_103_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The images we downloaded contain both hard and easy to predict images,
harder ones are those which is not easy to distinguish/containing
similar features with respect to few other classes while easier ones are
those which have some unique structural difference between the sign
formation and other features.

Here from the selected/downloaded images harder ones can be considered
as the speed limit traffic signs, whereas the easier ones are turn left
and right of way intersection traffic signs.

In our case the model trained so well it is clearly able to perdict all
the downloaded images.

    \subsubsection{Question 3:2. Discuss the model's predictions on these
new traffic signs and compare the results to predicting on the test set.
At a minimum, discuss what the predictions were, the accuracy on these
new predictions, and compare the accuracy to the accuracy on the test
set.}\label{question-32.-discuss-the-models-predictions-on-these-new-traffic-signs-and-compare-the-results-to-predicting-on-the-test-set.-at-a-minimum-discuss-what-the-predictions-were-the-accuracy-on-these-new-predictions-and-compare-the-accuracy-to-the-accuracy-on-the-test-set.}

    \paragraph{Answer:}\label{answer}

    \subsubsection{Predict the Sign Type for Each
Image}\label{predict-the-sign-type-for-each-image}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{k}{def} \PY{n+nf}{predict\PYZus{}new\PYZus{}img}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}array}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
                 \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{saver}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{DIR}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VGGNet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
                 \PY{n}{y\PYZus{}prob}\PY{p}{,} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{top\PYZus{}k}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{logits}\PY{p}{)}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{n}{k}\PY{p}{)}\PY{p}{,} 
                                      \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:}\PY{n}{new\PYZus{}imgs\PYZus{}array}\PY{p}{,} \PY{n}{keep\PYZus{}prob}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}prob\PYZus{}conv}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{\PYZcb{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{y\PYZus{}prob}\PY{p}{,} \PY{n}{y\PYZus{}pred}
         
         \PY{n}{y\PYZus{}prob}\PY{p}{,} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{predict\PYZus{}new\PYZus{}img}\PY{p}{(}\PY{n}{preprocessed\PYZus{}new\PYZus{}imgs}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from Saved\_Models\textbackslash{}VGGNet

    \end{Verbatim}

    \subsubsection{Analyze Performance}\label{analyze-performance}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{c+c1}{\PYZsh{} Extract file name(without . extension), I have used their ground truth labels when naming.}
         \PY{n}{ground\PYZus{}truth\PYZus{}labels} \PY{o}{=} \PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{n}{new\PYZus{}img\PYZus{}names}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{new\PYZus{}img\PYZus{}names}\PY{p}{)}\PY{p}{)}\PY{p}{]} 
         \PY{n}{new\PYZus{}imgs\PYZus{}accuracy} \PY{o}{=} \PY{l+m+mi}{0}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{preprocessed\PYZus{}new\PYZus{}imgs}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n}{ground\PYZus{}truth\PYZus{}labels}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{==} \PY{n}{y\PYZus{}pred}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{:}
                 \PY{n}{new\PYZus{}imgs\PYZus{}accuracy} \PY{o}{+}\PY{o}{=} \PY{l+m+mf}{0.2}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Prediction accuracy on new images = }\PY{l+s+si}{\PYZob{}:.1f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}accuracy}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Prediction accuracy on new images = 100.0\%

    \end{Verbatim}

    The model was able to correctly guess 5 of the 5 traffic signs, which
gives an accuracy of 100\%. This compares favorably to the accuracy on
the test set of 98.0\%.

    \subsubsection{Output Top 5 Softmax Probabilities For Each Image Found
on the
Web}\label{output-top-5-softmax-probabilities-for-each-image-found-on-the-web}

    For each of the new images, print out the model's softmax probabilities
to show the \textbf{certainty} of the model's predictions (limit the
output to the top 5 probabilities for each image).
\href{https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html\#top_k}{\texttt{tf.nn.top\_k}}
could prove helpful here.

The example below demonstrates how tf.nn.top\_k can be used to find the
top k predictions for each image.

\texttt{tf.nn.top\_k} will return the values and indices (class ids) of
the top k predictions. So if k=3, for each sign, it'll return the 3
largest probabilities (out of a possible 43) and the correspoding class
ids.

Take this numpy array as an example. The values in the array represent
predictions. The array contains softmax probabilities for five candidate
images with six possible classes. \texttt{tf.nn.top\_k} is used to
choose the three classes with the highest probability:

\begin{verbatim}
# (5, 6) array
a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,
         0.12789202],
       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,
         0.15899337],
       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,
         0.23892179],
       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,
         0.16505091],
       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,
         0.09155967]])
\end{verbatim}

Running it through \texttt{sess.run(tf.nn.top\_k(tf.constant(a),\ k=3))}
produces:

\begin{verbatim}
TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],
       [ 0.28086119,  0.27569815,  0.18063401],
       [ 0.26076848,  0.23892179,  0.23664738],
       [ 0.29198961,  0.26234032,  0.16505091],
       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],
       [0, 1, 4],
       [0, 5, 1],
       [1, 3, 5],
       [1, 4, 3]], dtype=int32))
\end{verbatim}

Looking just at the first row we get
\texttt{{[}\ 0.34763842,\ \ 0.24879643,\ \ 0.12789202{]}}, you can
confirm these are the 3 largest probabilities in \texttt{a}. You'll also
notice \texttt{{[}3,\ 0,\ 5{]}} are the corresponding indices.

    \subsubsection{Question 3:3 Describe how certain the model is when
predicting on each of the five new images by looking at the softmax
probabilities for each prediction. Provide the top 5 softmax
probabilities for each image along with the sign type of each
probability.}\label{question-33-describe-how-certain-the-model-is-when-predicting-on-each-of-the-five-new-images-by-looking-at-the-softmax-probabilities-for-each-prediction.-provide-the-top-5-softmax-probabilities-for-each-image-along-with-the-sign-type-of-each-probability.}

    \paragraph{Answer:}\label{answer}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         \PY{n}{prediction\PYZus{}indices} \PY{o}{=} \PY{p}{[}\PY{n}{l}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{l} \PY{o+ow}{in} \PY{n}{y\PYZus{}pred}\PY{p}{]}
         \PY{n}{predicitons\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{n}{signs}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{n}{idx}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{idx} \PY{o+ow}{in} \PY{n}{prediction\PYZus{}indices}\PY{p}{]}
         \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}colwidth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}prob}\PY{p}{,} \PY{n}{prediction\PYZus{}indices}\PY{p}{,} \PY{n}{predicitons\PYZus{}values}\PY{p}{)}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Indices}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Probabilities}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted Index}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}49}]:}                 Indices  \textbackslash{}
         0       [1, 2, 5, 4, 0]   
         1    [11, 30, 27, 0, 1]   
         2  [18, 26, 28, 27, 20]   
         3      [3, 5, 2, 15, 9]   
         4   [34, 38, 35, 9, 37]   
         
                                                               Probabilities  \textbackslash{}
         0    [1.0, 3.722121e-21, 8.712576e-24, 4.5527434e-26, 5.371315e-29]   
         1                     [1.0, 2.3282428e-26, 1.1189527e-36, 0.0, 0.0]   
         2    [1.0, 1.8305154e-14, 1.866918e-18, 3.32546e-20, 7.2192254e-26]   
         3    [1.0, 1.9240574e-11, 2.0744442e-17, 1.9943938e-26, 9.2066e-31]   
         4  [1.0, 2.9233479e-18, 1.4390196e-19, 1.2648935e-25, 1.732376e-26]   
         
            Predicted Index                        Predicted Value  
         0                1                   Speed limit (30km/h)  
         1               11  Right-of-way at the next intersection  
         2               18                        General caution  
         3                3                   Speed limit (60km/h)  
         4               34                        Turn left ahead  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{n}{y\PYZus{}prob}\PY{p}{,} \PY{n}{y\PYZus{}pred}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}50}]:} (array([[1.0000000e+00, 3.7221209e-21, 8.7125758e-24, 4.5527434e-26,
                  5.3713151e-29],
                 [1.0000000e+00, 2.3282428e-26, 1.1189527e-36, 0.0000000e+00,
                  0.0000000e+00],
                 [1.0000000e+00, 1.8305154e-14, 1.8669179e-18, 3.3254599e-20,
                  7.2192254e-26],
                 [1.0000000e+00, 1.9240574e-11, 2.0744442e-17, 1.9943938e-26,
                  9.2065996e-31],
                 [1.0000000e+00, 2.9233479e-18, 1.4390196e-19, 1.2648935e-25,
                  1.7323760e-26]], dtype=float32), array([[ 1,  2,  5,  4,  0],
                 [11, 30, 27,  0,  1],
                 [18, 26, 28, 27, 20],
                 [ 3,  5,  2, 15,  9],
                 [34, 38, 35,  9, 37]]))
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{n}{preprocessed\PYZus{}new\PYZus{}imgs}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}51}]:} (32, 32, 1)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{o}{*}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{new\PYZus{}imgs\PYZus{}container}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{signs}\PY{p}{[}\PY{n}{y\PYZus{}pred}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{o}{*}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{2}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{barh}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{y\PYZus{}prob}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{p}{)}
             \PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{n}{signs}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n}{y\PYZus{}pred}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]}
             \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{labels}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_119_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Our trained model was able to predict very confidently on all the
downloaded images with a very high probabilities. The model attained an
accuracy of 100\% at prediction on these downloaded images.

However if we inspect the actual probabilites in case where the ground
truth is 'Speed limit(80km/h)' we do notice that model also has a
relatively higher probability(not very noticeably) for 'Speed
limit(80km/h)'.

    \subsubsection{Project Writeup}\label{project-writeup}

Once you have completed the code implementation, document your results
in a project writeup using this
\href{https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md}{template}
as a guide. The writeup can be in a markdown or pdf file.

    \begin{quote}
\textbf{Note}: Once you have completed all of the code implementations
and successfully answered each question above, you may finalize your
work by exporting the iPython Notebook as an HTML document. You can do
this by using the menu above and navigating to \n", "\textbf{File
-\textgreater{} Download as -\textgreater{} HTML (.html)}. Include the
finished document along with this notebook as your submission.
\end{quote}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Step 4 (Optional): Visualize the Neural Network's State with
Test
Images}\label{step-4-optional-visualize-the-neural-networks-state-with-test-images}

This Section is not required to complete but acts as an additional
excersise for understaning the output of a neural network's weights.
While neural networks can be a great learning device they are often
referred to as a black box. We can understand what the weights of a
neural network look like better by plotting their feature maps. After
successfully training your neural network you can see what it's feature
maps look like by plotting the output of the network's weight layers in
response to a test stimuli image. From these plotted feature maps, it's
possible to see what characteristics of an image the network finds
interesting. For a sign, maybe the inner network feature maps react with
high activation to the sign's boundary outline or to the contrast in the
sign's painted symbol.

Provided for you below is the function code that allows you to get the
visualization output of any tensorflow weight layer you want. The inputs
to the function should be a stimuli image, one used during training or a
new one you provided, and then the tensorflow variable name that
represents the layer's state during the training process, for instance
if you wanted to see what the
\href{https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81}{LeNet
lab's} feature maps looked like for it's second convolutional layer you
could enter conv2 as the tf\_activation variable.

For an example of what feature map outputs look like, check out NVIDIA's
results in their paper
\href{https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/}{End-to-End
Deep Learning for Self-Driving Cars} in the section Visualization of
internal CNN State. NVIDIA was able to show that their network's inner
weights had high activations to road boundary lines by comparing feature
maps from an image with a clear path to one without. Try experimenting
with a similar test to show that your trained network's weights are
looking for interesting features, whether it's looking at differences in
feature maps from images with or without a sign, or even what feature
maps look like in a trained network vs a completely untrained one on the
same sign image.

Your output should look something like this (above)

    \subsubsection{Question 4:1 Discuss the visual output of your trained
network's feature maps. What characteristics did the neural network use
to make
classifications?}\label{question-41-discuss-the-visual-output-of-your-trained-networks-feature-maps.-what-characteristics-did-the-neural-network-use-to-make-classifications}

    \paragraph{Answer:}\label{answer}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Visualize your network\PYZsq{}s feature maps here.}
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Feel free to use as many code cells as needed.}
         
         \PY{c+c1}{\PYZsh{} image\PYZus{}input: the test image being fed into the network to produce the feature maps}
         \PY{c+c1}{\PYZsh{} tf\PYZus{}activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer}
         \PY{c+c1}{\PYZsh{} activation\PYZus{}min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output}
         \PY{c+c1}{\PYZsh{} plt\PYZus{}num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry}
         
         \PY{k}{def} \PY{n+nf}{outputFeatureMap}\PY{p}{(}\PY{n}{image\PYZus{}input}\PY{p}{,} \PY{n}{tf\PYZus{}activation}\PY{p}{,} \PY{n}{activation\PYZus{}min}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{activation\PYZus{}max}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1} \PY{p}{,}\PY{n}{plt\PYZus{}num}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Here make sure to preprocess your image\PYZus{}input in a way your network expects}
             \PY{c+c1}{\PYZsh{} with size, normalization, ect if needed}
             \PY{c+c1}{\PYZsh{} image\PYZus{}input =}
             \PY{c+c1}{\PYZsh{} Note: x should be the same name as your network\PYZsq{}s tensorflow data placeholder variable}
             \PY{c+c1}{\PYZsh{} If you get an error tf\PYZus{}activation is not defined it may be having trouble accessing the variable from inside a function}
             \PY{n}{activation} \PY{o}{=} \PY{n}{tf\PYZus{}activation}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{n}{session}\PY{o}{=}\PY{n}{sess}\PY{p}{,}\PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{x} \PY{p}{:} \PY{n}{image\PYZus{}input}\PY{p}{\PYZcb{}}\PY{p}{)}
             \PY{n}{featuremaps} \PY{o}{=} \PY{n}{activation}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}
             \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{plt\PYZus{}num}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
             \PY{k}{for} \PY{n}{featuremap} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{featuremaps}\PY{p}{)}\PY{p}{:}
                 \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{featuremap}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} sets the number of feature maps to show on each row and column}
                 \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FeatureMap }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{featuremap}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} displays the feature map number}
                 \PY{k}{if} \PY{n}{activation\PYZus{}min} \PY{o}{!=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1} \PY{o}{\PYZam{}} \PY{n}{activation\PYZus{}max} \PY{o}{!=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}
                     \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{activation}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,} \PY{n}{featuremap}\PY{p}{]}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{nearest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{vmin} \PY{o}{=}\PY{n}{activation\PYZus{}min}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{n}{activation\PYZus{}max}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{k}{elif} \PY{n}{activation\PYZus{}max} \PY{o}{!=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}
                     \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{activation}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,} \PY{n}{featuremap}\PY{p}{]}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{nearest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{n}{activation\PYZus{}max}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{k}{elif} \PY{n}{activation\PYZus{}min} \PY{o}{!=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}
                     \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{activation}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,} \PY{n}{featuremap}\PY{p}{]}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{nearest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{vmin}\PY{o}{=}\PY{n}{activation\PYZus{}min}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{activation}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,} \PY{n}{featuremap}\PY{p}{]}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{nearest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \paragraph{Load test stimuli image}\label{load-test-stimuli-image}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{n}{stimuli\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}new\PYZus{}images/1.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{stimuli\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{stimuli\PYZus{}img}\PY{p}{,} \PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}BGR2RGB}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Nest/Contain stimuli image in a container to add a 4th dimension}
         \PY{n}{stimuli\PYZus{}array} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{p}{[}\PY{n}{stimuli\PYZus{}img}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Pass stimuli image through preprocessor}
         \PY{n}{preprocessed\PYZus{}stimuli\PYZus{}array} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{stimuli\PYZus{}array}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{n}{fig\PYZus{}stim}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
         \PY{n}{ax1}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{stimuli\PYZus{}img}\PY{p}{)}
         \PY{n}{ax2}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{preprocessed\PYZus{}stimuli\PYZus{}array}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}55}]:} <matplotlib.image.AxesImage at 0x2387edb1160>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_129_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{c+c1}{\PYZsh{} def predict\PYZus{}y\PYZus{}single\PYZus{}img(preprocessed\PYZus{}stimuli\PYZus{}array):}
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{n}{VGGNet\PYZus{}Model}\PY{o}{.}\PY{n}{saver}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{DIR}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VGGNet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{conv\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Conv2D\PYZus{}1:0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{outputFeatureMap}\PY{p}{(}\PY{n}{preprocessed\PYZus{}stimuli\PYZus{}array}\PY{p}{,} \PY{n}{conv\PYZus{}layer}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from Saved\_Models\textbackslash{}VGGNet

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_130_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{c+c1}{\PYZsh{} with tf.Session() as sess:}
         \PY{c+c1}{\PYZsh{}     VGGNet\PYZus{}Model.saver.restore(sess, os.path.join(DIR, \PYZdq{}VGGNet\PYZdq{}))}
         \PY{c+c1}{\PYZsh{}     op = sess.graph.get\PYZus{}operations()}
         \PY{c+c1}{\PYZsh{}     print([m.values() for m in op])}
\end{Verbatim}


    \subsubsection{Below Answer for 'Question 2:4' as mentioned
above}\label{below-answer-for-question-24-as-mentioned-above}

    \paragraph{Question 2:4. Describe the approach taken for finding a
solution and getting the validation set accuracy to be at least 0.93.
Include in the discussion the results on the training, validation and
test sets and where in the code these were calculated. Your approach may
have been an iterative process, in which case, outline the steps you
took to get to the final solution and why you chose those steps. Perhaps
your solution involved an already well known implementation or
architecture. In this case, discuss why you think the architecture is
suitable for the current
problem.}\label{question-24.-describe-the-approach-taken-for-finding-a-solution-and-getting-the-validation-set-accuracy-to-be-at-least-0.93.-include-in-the-discussion-the-results-on-the-training-validation-and-test-sets-and-where-in-the-code-these-were-calculated.-your-approach-may-have-been-an-iterative-process-in-which-case-outline-the-steps-you-took-to-get-to-the-final-solution-and-why-you-chose-those-steps.-perhaps-your-solution-involved-an-already-well-known-implementation-or-architecture.-in-this-case-discuss-why-you-think-the-architecture-is-suitable-for-the-current-problem.}

    \paragraph{Answer:}\label{answer}

    \subsection{Conclusion}\label{conclusion}

My final model results are: * Training set accuracy of 100\% *
Validation set accuracy of 99.5\% * Test set accuracy of 98\%

The first architecture I tried was traditional LeNet which was taught in
the lesson itself, but with LeNet after training it sufficiently enough
on the training data it still couldn't generalize well to the test set.
LeNet model is in itself a remarkable architecture to understand
features in an image but to capture the low details in order to
generalize towards even more data it isn't deep enough, so my next
approach was to look for other well-known architectures that could
capture the low level features essentially the ones which are deep
enough yet balance the number of parameters.

VGGNet architecture as described previously was chosen in an intension
to give enough room for our architecture to understand the features and
have as many layers to distinguish out smaller combinations of features
in the input image leading to a much better prediction.

Using VGGNet, we've been able to reach a very high accuracy rate. We can
also try to explore other pre-processing techniques to further improve
the model's accuracy. It is obvious for our model to not perform well on
images which aren't very clear because of cases like motion blur effect
or extreme over exposure which totally disrupts the features of the
traffic sign which are essential to classify them in the first place.
Given all that this model is fine tuned and deep enough to classify and
make sense out of any images of the classes which were used for
training, but would surely fail on images of any other arbitrary classes
which it doesn't know.

Overall our model achieved a classification accuracy of 98\% over test
set, 99.5\% accuracy over validation set and also the model correctly
identified all new downloaded images.

Unfortunately, there are two major drawbacks with VGGNet: * It is
painfully slow to train. * The network architecture weights themselves
are quite large (in terms of disk/bandwidth).

It is proven with emergence of new architectures that the size and depth
of the model doesn't always factor in to attain a higher accuracy,
however inferior VGGNet is we still can use VGG(not as efficiently) in
many deep learning image classification problems, however, smaller
network architectures are often more desirable (such as SqueezeNet,
GoogLeNet, etc.).


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
